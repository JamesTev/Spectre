{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpectreDBDataProcessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Sg6_fExyAx"
      },
      "source": [
        "TODO: - Look at Mean of empty slice error, that has to do with the amount of readings we take per sample. IMO 3 is too low, 5 or more are needed and that should solve the problem.\r\n",
        "-Normalisation of data before Inputting into the ML algorithm\r\n",
        "\r\n",
        "Latest Update: Accounted for the calibration set which was recently added in the api."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prQ1biUVqK8q",
        "outputId": "3c3c3075-0bf2-4244-93f7-e9fabd783209"
      },
      "source": [
        "import pymongo\r\n",
        "import pprint\r\n",
        "import numpy as np\r\n",
        "!pip install dnspython\r\n",
        "\r\n",
        "#parsing db\r\n",
        "dbase = \"philip_test_db\" #change db access here\r\n",
        "root_pwd = \"Spectre2020\"\r\n",
        "client = pymongo.MongoClient(f\"mongodb+srv://root:{root_pwd}@cluster0.sn2un.mongodb.net/{dbase}?retryWrites=true&w=majority\")\r\n",
        "\r\n",
        "\r\n",
        "db = client.philip_test_db.reading_set #remember to change the db name\r\n",
        "\r\n",
        "def printdb(instances):\r\n",
        "  print('Records in Database: ' + str(db.count()))\r\n",
        "  for record in db.find().limit(instances):\r\n",
        "      pprint.pprint(record)\r\n",
        "\r\n",
        "\r\n",
        "#printdb(2) #use if you want to see how many records are in the db and print some instances raw, set by the instances input i.e. 2 in this case"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: dnspython in /usr/local/lib/python3.6/dist-packages (2.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "ZUDcj91z52Q2",
        "outputId": "b7ea2e5f-7790-458c-a8b6-298b0726ef86"
      },
      "source": [
        "import pandas as pd\r\n",
        "from pandas import json_normalize\r\n",
        "\r\n",
        "#inserting db into a dataframe\r\n",
        "\r\n",
        "datapoints = list(db.find({}))\r\n",
        "df = json_normalize(datapoints)\r\n",
        "df.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>_cls</th>\n",
              "      <th>ref</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>readings</th>\n",
              "      <th>calibration_readings</th>\n",
              "      <th>sample_name</th>\n",
              "      <th>sample_descr</th>\n",
              "      <th>adulterant_type</th>\n",
              "      <th>api_type</th>\n",
              "      <th>solvent</th>\n",
              "      <th>adulterant_mass</th>\n",
              "      <th>api_mass</th>\n",
              "      <th>solvent_vol</th>\n",
              "      <th>device_id</th>\n",
              "      <th>params.exposure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>601ecc8f246c632636519e0b</td>\n",
              "      <td>ReadingSet</td>\n",
              "      <td>1612631181</td>\n",
              "      <td>2021-02-06 19:06:21.021</td>\n",
              "      <td>[{'set_ref': '1612631181', 'timestamp': 2021-0...</td>\n",
              "      <td>[{'set_ref': '1612631181', 'timestamp': 2021-0...</td>\n",
              "      <td>test</td>\n",
              "      <td>test</td>\n",
              "      <td>white sugar</td>\n",
              "      <td>paracetamol</td>\n",
              "      <td>distilled water (room temp)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Test</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>601ed158684d79db6db4ac2d</td>\n",
              "      <td>ReadingSet</td>\n",
              "      <td>1612632408</td>\n",
              "      <td>2021-02-06 17:26:48.344</td>\n",
              "      <td>[{'set_ref': '1612632408', 'timestamp': 2021-0...</td>\n",
              "      <td>[{'set_ref': '1612632408', 'timestamp': 2021-0...</td>\n",
              "      <td>Test Anh</td>\n",
              "      <td>test</td>\n",
              "      <td>white sugar</td>\n",
              "      <td>paracetamol</td>\n",
              "      <td>distilled water (room temp)</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Test</td>\n",
              "      <td>2000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        _id        _cls  ... device_id params.exposure\n",
              "0  601ecc8f246c632636519e0b  ReadingSet  ...      Test            2000\n",
              "1  601ed158684d79db6db4ac2d  ReadingSet  ...      Test            2000\n",
              "\n",
              "[2 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKVClDr1Ami7",
        "outputId": "987e23df-281b-483d-d168-93b387ef7c18"
      },
      "source": [
        "#extracting spectrogram values from readings and calibration readings\r\n",
        "def extracting_readings(db,df,db_readings):\r\n",
        "  for i in range(db.count()): #number of records\r\n",
        "    #print(i)\r\n",
        "    for j in range(len(df[db_readings][i])): #number of samples per record\r\n",
        "      #print(j)\r\n",
        "      readings = df[db_readings][i][j]['values']\r\n",
        "      #print(f\"readings: {readings}\")\r\n",
        "      if i == 0 and j == 0:\r\n",
        "        readings_arr = np.array(readings)\r\n",
        "      else:\r\n",
        "        readings_arr = np.vstack((readings_arr, readings)) #readings_arr is the output numpy matrix for our sample data\r\n",
        "    \r\n",
        "  return readings_arr\r\n",
        "\r\n",
        "#extracting spectrogram values from readings\r\n",
        "readings_arr = extracting_readings(db,df,\"readings\")\r\n",
        "#extracting spectrogram values from calibration readings\r\n",
        "cal_readings_arr = extracting_readings(db,df,\"calibration_readings\")\r\n",
        "\r\n",
        "print(readings_arr.shape)\r\n",
        "print(cal_readings_arr.shape)\r\n",
        "\r\n",
        "#extracting spectrogram labels\r\n",
        "#the part below is for check purposes, we are creating labels in the next code section\r\n",
        "for i in range(db.count()):\r\n",
        "  #print(i)\r\n",
        "  for j in range(len(df['readings'][i])):\r\n",
        "    #print(j)\r\n",
        "    r_labels = df['sample_name'][i] +  df['adulterant_type'][i] + df['api_type'][i] + df['solvent'][i]\r\n",
        "    #print(\"labels: \" + r_labels)\r\n",
        "    if i == 0 and j == 0:\r\n",
        "      labels_arr = np.array(r_labels)\r\n",
        "    else:\r\n",
        "      labels_arr = np.vstack((labels_arr, r_labels)) #labels_arr is the output numpy matrix for our sample labels\r\n",
        "\r\n",
        "print(labels_arr.shape)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(6, 128)\n",
            "(6, 128)\n",
            "(6, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zhgn-x711rv_",
        "outputId": "3d0f8d4a-282a-456b-fe82-d23185d14573"
      },
      "source": [
        "def reject_outliers_and_avg(db,df,readings_arr, m, db_readings):\r\n",
        "    clean_data = np.array([])\r\n",
        "    for i in range(db.count()): #number of records\r\n",
        "      for k in range(128):  #for the sake of saving some computational power we can just explicitly write down the number of spectral data points per sample\r\n",
        "         d = readings_arr[:len(df[db_readings][i]),k]\r\n",
        "         outlier_rejection = d[abs(d - np.mean(d)) < m * np.std(d)] #excluding outliers\r\n",
        "         clean_data_mean = np.mean(outlier_rejection)\r\n",
        "         clean_data = np.append(clean_data, clean_data_mean, axis=None) #forming the data matrix again\r\n",
        "\r\n",
        "    clean_data = np.reshape(clean_data, (db.count(),128))\r\n",
        "    return clean_data\r\n",
        "\r\n",
        "def labels_for_cleaned_data(db,df):\r\n",
        "  for i in range(db.count()):\r\n",
        "    #The below string, forming the labels, should be edited to represent an agreed consensus\r\n",
        "    fetch_labels = df['sample_name'][i] +  df['adulterant_type'][i] + df['api_type'][i] + df['solvent'][i] + str(df['adulterant_mass'][i]) + str(df['api_mass'][i]) + str(df['solvent_vol'][i])\r\n",
        "    if i == 0:\r\n",
        "      labels = np.array(fetch_labels)\r\n",
        "    else:\r\n",
        "      labels = np.vstack((labels, fetch_labels))\r\n",
        "  \r\n",
        "  return labels\r\n",
        "\r\n",
        "clean_sample_data = reject_outliers_and_avg(db,df,readings_arr, 1.2, \"readings\") #change m accordingly=========\r\n",
        "clean_cal_data = reject_outliers_and_avg(db,df,cal_readings_arr, 1.2, \"calibration_readings\") #change m accordingly=========\r\n",
        "clean_labels = labels_for_cleaned_data(db,df)\r\n",
        "\r\n",
        "print(\"Labels for cleaned data: \\n\", clean_labels)\r\n",
        "print(\"Calibration data shape(post-clean): \\n\", clean_cal_data.shape)\r\n",
        "print(\"Sample data shape(post-clean): \\n\", clean_sample_data.shape)\r\n",
        "print(\"Labels shape(for cleaned data): \\n\", clean_labels.shape)\r\n",
        "\r\n",
        "#print(clean_cal_data)\r\n",
        "#print(clean_data)\r\n",
        "\r\n",
        "#=================================================================================================================\r\n",
        "##IMPORTANT========================================================================================================\r\n",
        "#NEED TO FIX MEAN OF EMPTY SLICE===================================================================================\r\n",
        "##IMPORTANT========================================================================================================\r\n",
        "#=================================================================================================================="
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Labels for cleaned data: \n",
            " [['testwhite sugarparacetamoldistilled water (room temp)0.00.00.0']\n",
            " ['Test Anhwhite sugarparacetamoldistilled water (room temp)0.00.00.0']]\n",
            "Calibration data shape(post-clean): \n",
            " (2, 128)\n",
            "Sample data shape(post-clean): \n",
            " (2, 128)\n",
            "Labels shape(for cleaned data): \n",
            " (2, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEIX39yAwKPy"
      },
      "source": [
        "# Creating our input data for our ML algorithms bu subtracting sample data from calibration data\r\n",
        "#Normalisation to the cleaned data has not yet been applied\r\n",
        "MLData = np.subtract(clean_cal_data,clean_sample_data)\r\n",
        "\r\n",
        "#TODO HERE ==> More data preprocessing i.e. noramlisation/standardization\r\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGP7RUp_GoFM",
        "outputId": "eaa22504-e1f4-431b-baae-68bdd4f04828"
      },
      "source": [
        "#ML IMPLEMENTATION GOES HERE\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Activation, BatchNormalization\r\n",
        "from keras.utils import np_utils\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.optimizers import RMSprop\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "# the data, shuffled and split between train and test sets\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(MLData, clean_labels)\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(x_test.shape)\r\n",
        "print(y_train.shape)\r\n",
        "print(y_test.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 128)\n",
            "(1, 128)\n",
            "(1, 1)\n",
            "(1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2wE28xd4kdp"
      },
      "source": [
        "##IGNORE FOR NOW\r\n",
        "\r\n",
        "##TESTING outlier algo================NOT USED in pipeline=======================\r\n",
        "#jk = np.array([2.35294118,1.56862745,1.56862745,3.1372549, 4.56862745])\r\n",
        "#def outlier_rej(d):\r\n",
        "#  return data[abs(d - np.mean(d)) < 1.5 * np.std(d)]\r\n",
        "#t_d = outlier_rej(jk)\r\n",
        "#print(t_d)\r\n",
        "##=============================m of 1.2 seems sensible===========================\r\n",
        "##BUT, 1.5 might be more realistic to the obtained readings======================"
      ],
      "execution_count": 65,
      "outputs": []
    }
  ]
}
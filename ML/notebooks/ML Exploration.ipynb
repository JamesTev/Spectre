{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BfRbwinZXWYl"
   },
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# !pip install dnspython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_AhMNPfjXZ8s"
   },
   "outputs": [],
   "source": [
    "import mongoengine as me\n",
    "\n",
    "db_name = \"spectre_db\" #change db access here\n",
    "root_pwd = \"\" # add password\n",
    "\n",
    "db_uri = f\"mongodb+srv://root:{root_pwd}@cluster0.sn2un.mongodb.net/{db_name}?retryWrites=true&w=majority\"\n",
    "client = pymongo.MongoClient(db_uri)\n",
    "\n",
    "db = client.spectre_db.reading_set #remember to change the db name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "y-e-8zlwX8QH",
    "outputId": "0499cabc-86df-45c5-a69a-0713b49c91f6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#inserting db into a dataframe\n",
    "\n",
    "datapoints = list(db.find({'device_id':'jt_spec_1'}))\n",
    "df_all = pd.json_normalize(datapoints)\n",
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_HEcFZhaRwX",
    "outputId": "33abf66d-ee2a-4a2a-ab95-4f39f9bf59a8"
   },
   "outputs": [],
   "source": [
    "cols = ['timestamp', 'readings', 'calibration_readings', 'sample_name', 'api_type', 'ref']\n",
    "df = df_all[cols].reset_index()\n",
    "set1 = df.readings[0]\n",
    "\n",
    "def proc_readingset(row):\n",
    "    X = np.array([reading['values'] for reading in row['readings']])\n",
    "    X_cal = np.array([reading['values'] for reading in row['calibration_readings']])\n",
    "    out = row[['timestamp', 'sample_name', 'api_type', 'ref', 'index']].to_dict()\n",
    "    out.update({\n",
    "        'X': X,\n",
    "        'X_cal': X_cal\n",
    "    })\n",
    "    return out\n",
    "\n",
    "lbl_fmt = lambda s: s.lower().rstrip(' ').replace(' ', '_')\n",
    "df_proc = df.apply(proc_readingset, axis=1)\n",
    "set([f\"{el['index']}: {lbl_fmt(el['api_type'])} - {el['sample_name']}\" for el in df_proc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[cols].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8YqbPKuPQxiD"
   },
   "outputs": [],
   "source": [
    "target_apis = ['sb_semillon', 'chenin']\n",
    "target_apis = ['ia', 'got'] # gin\n",
    "target_apis = ['dw', 'jam'] # whisky\n",
    "target_apis = ['a', 'm'] # vinegar 2 (apple cider, malt)\n",
    "\n",
    "# target_apis = ['o', 's'] \n",
    "\n",
    "# target_apis = ['apple cider vinegar', 'malt vinegar']\n",
    "\n",
    "def extract_api_data(api, df_proc):\n",
    "    lbl_fmt = lambda s: s.lower().rstrip(' ').replace(' ', '_')\n",
    "    data = {'X':[], 'X_cal':[], 'sample_names': [], 'refs': [], 'timestamps': []}\n",
    "    \n",
    "    for row in df_proc:\n",
    "        if lbl_fmt(row['api_type']) == api:\n",
    "            data['X'].append(row['X'])\n",
    "            data['X_cal'].append(row['X_cal'])\n",
    "            data['sample_names'].append(row['sample_name'])\n",
    "            data['refs'].append(row['ref'])\n",
    "            data['timestamps'].append(row['timestamp'])\n",
    "\n",
    "    for k in ['X', 'X_cal']: # convert to numpy matrices\n",
    "        Xm = np.array([np.mean(sample_set, axis=0) for sample_set in data[k]])\n",
    "        data[k] = Xm\n",
    "    \n",
    "    data['X_rel'] = (data['X']/data['X_cal'])\n",
    "    return data\n",
    "\n",
    "data = {api:None for api in target_apis}\n",
    "for api in target_apis:\n",
    "    data[api] = extract_api_data(api, df_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "fM5p2ZfQVETY",
    "outputId": "a3ccac4a-889d-4c50-b20d-7eba2a11498a"
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,len(target_apis), figsize=(14,6), sharey=True)\n",
    "for i in range(len(target_apis)):\n",
    "    api = target_apis[i]\n",
    "    axes[i].plot(data[api]['X_rel'].T)\n",
    "#     axes[i].legend(data[api]['refs'])\n",
    "    print(data[api]['refs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkFFh5DWjcQA"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def form_dataset(data_map, key='X_rel'):\n",
    "    X = None\n",
    "    y = None\n",
    "    for i, (api, data) in enumerate(data_map.items()):\n",
    "        if X is None:\n",
    "            X = data[key]\n",
    "            y = np.ones(data[key].shape[0])*i\n",
    "        else:\n",
    "            X = np.r_[X, data[key]]\n",
    "            y = np.r_[y, np.ones(data[key].shape[0])*i]\n",
    "            \n",
    "    X = np.array(X).reshape(-1, 128)\n",
    "    y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = form_dataset(data)\n",
    "\n",
    "# Xnorm = ((X-np.mean(X))/np.std(X)).T\n",
    "# C = Xnorm.dot(Xnorm.T)\n",
    "\n",
    "# lam, A = np.linalg.eig(C)\n",
    "\n",
    "# Xprime = A[:, 1:4].T.dot(Xnorm)\n",
    "# Xprime = np.real(Xprime.T)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w6Y-BJ-Sov-8",
    "outputId": "1cb87d52-abd9-4144-c0db-ce4a07586d4e"
   },
   "outputs": [],
   "source": [
    "sigmoid = lambda x: 1/(1+np.e**-x)\n",
    "\n",
    "w = np.linalg.pinv(X_train).dot(y_train)\n",
    "y_pred = sigmoid(X_test.dot(w))\n",
    "\n",
    "print(f\"y: {y_test.flatten().T}, y pred: {y_pred.round(decimals=2).flatten().T}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F63Bpl5Ip21C"
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "def shift_matrix(X, delta):\n",
    "    \"\"\"Expects X to be a [samples x features] matrix\"\"\"\n",
    "    X_shift = np.zeros_like(X)\n",
    "    for i in range(X.shape[0]):\n",
    "        X_shift[i, :] = shift(X[i, :], delta, mode='nearest')\n",
    "    return X_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rc0qBu5PqqLZ",
    "outputId": "6231152f-b74f-461f-cfe3-3f53075e79e3"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.e**(-x))\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    X_test = shift_matrix(X_test, 4)\n",
    "\n",
    "    w = np.linalg.pinv(X_train).dot(y_train)\n",
    "    y_pred = X_test.dot(w).round(decimals=2)\n",
    "    y_pred_bin = np.maximum(np.round(y_pred), 0)\n",
    "    print(accuracy_score(y_pred_bin, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "nyZq01GEHCAJ",
    "outputId": "d31333b6-be53-4d8a-ddc1-944d75d5ef25"
   },
   "outputs": [],
   "source": [
    "delta_range = list(range(-25, 25))\n",
    "accs = []\n",
    "for d in delta_range:\n",
    "    X_test_sh = shift_matrix(X_test, d)\n",
    "\n",
    "    w = np.linalg.pinv(X_train).dot(y_train)\n",
    "    y_pred = X_test_sh.dot(w).round(decimals=2)\n",
    "    y_pred_bin = np.maximum(np.round(y_pred), 0)\n",
    "\n",
    "    acc=accuracy_score(y_pred_bin, y_test)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(delta_range, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "kbc6W-DHRe2W",
    "outputId": "07ffba20-2f6a-478e-e493-df3f572d4a53"
   },
   "outputs": [],
   "source": [
    "X_tr_shift = shift_matrix(X_train, 5)\n",
    "plt.plot(np.squeeze(X_tr_shift[1, :]).T)\n",
    "plt.plot(np.squeeze(X_train[1, :]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 497
    },
    "id": "CAjFrwaMHiqn",
    "outputId": "88d0e7e7-2a7d-46f2-8da6-f024f6eee03a"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "pool_model = Sequential([\n",
    "        AveragePooling1D(pool_size=2,  name='first_pool')\n",
    "    ])\n",
    "\n",
    "def create_model(input_shape, n_outputs=1):\n",
    "    model = Sequential()\n",
    "    model.add(MaxPooling1D(pool_size=2,  name='first_pool', input_shape=input_shape))\n",
    "    model.add(Conv1D(filters=8, kernel_size=8, padding='same', activation='relu'))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=16, kernel_size=4, padding='same', activation='relu'))\n",
    "    model.add(AveragePooling1D(pool_size=2))\n",
    "    model.add(Conv1D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    out_act = 'sigmoid'\n",
    "    loss = 'binary_crossentropy'\n",
    "    if n_outputs > 1:\n",
    "        out_act = 'softmax'\n",
    "        loss = 'categorical_crossentropy'\n",
    "    model.add(Dense(n_outputs, activation=out_act))\n",
    "    model.compile(loss=loss, optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = X[train_index], X[test_index]\n",
    "y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "X_train_aug = X_train\n",
    "y_train_aug = y_train\n",
    "\n",
    "for delta in [-4, -2, 2, 4]: # data augmentation\n",
    "    X_shift = shift_matrix(X_train, delta)\n",
    "    X_train_aug = np.r_[X_train_aug, X_shift]\n",
    "    y_train_aug = np.r_[y_train_aug, y_train]\n",
    "\n",
    "X_train = X_train_aug\n",
    "X_test = shift_matrix(X_test, 0)\n",
    "\n",
    "X_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "K1Nh56Dyo7mx",
    "outputId": "e7056f45-e0ef-44fc-80b3-52ce5d9ea33b"
   },
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, shuffle=True, random_state=1) #random_state=123\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "cv_acc = []\n",
    "histories = []\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train_aug = X_train\n",
    "    y_train_aug = y_train\n",
    "\n",
    "    for delta in [-4, -2, 2, 4]: # data augmentation\n",
    "        X_shift = shift_matrix(X_train, delta)\n",
    "        X_train_aug = np.r_[X_train_aug, X_shift]\n",
    "        y_train_aug = np.r_[y_train_aug, y_train]\n",
    "    \n",
    "    rnd_idx = np.random.permutation(X_train_aug.shape[0])\n",
    "    X_train = X_train_aug[rnd_idx] # shuffle the augmented matrices\n",
    "    y_train = y_train_aug[rnd_idx]\n",
    "    X_test_sh = shift_matrix(X_test, 4)\n",
    "\n",
    "    # model input should be 3D tensor of [samples, time steps, features] (only 1 feature in our case)\n",
    "    X_train_win, X_test_win =  [Xi.reshape(Xi.shape[0], -1, 1) for Xi in (X_train, X_test_sh)]\n",
    "    y_train_win, y_test_win = y_train, y_test\n",
    "\n",
    "    epochs = 100\n",
    "    batch_size = 10\n",
    "\n",
    "    model = create_model(X_train_win.shape[1:])\n",
    "    hist = model.fit(X_train_win, y_train_win, validation_data=(X_test_win, y_test_win), epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    histories.append(hist.history)\n",
    "    _, acc = model.evaluate(X_test_win, y_test_win, batch_size=batch_size, verbose=1)\n",
    "    cv_acc.append(acc)\n",
    "\n",
    "print(f\"\\n\\nAccuracy across folds: {cv_acc}. Average: {np.mean(cv_acc)}\")\n",
    "plt.plot(hist.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hist in histories:\n",
    "    plt.plot(hist['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_train_win.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "fPHn4FudnxKu",
    "outputId": "3698a110-ada2-4bf5-9353-6cf43d50da82"
   },
   "outputs": [],
   "source": [
    "delta_range = list(range(-20, 20))\n",
    "accs = []\n",
    "for d in delta_range:\n",
    "    X_test_sh = shift_matrix(X_test, d)\n",
    "    X_test_sh = X_test_sh.reshape(X_test_sh.shape[0], -1, 1)\n",
    "    _, acc=model.evaluate(X_test_sh, y_test_win, verbose=0)\n",
    "    accs.append(acc)\n",
    "\n",
    "plt.plot(delta_range, accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Spectre James.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base-env",
   "language": "python",
   "name": "base-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
